/************************************************************************
* Copyright(c) 2016  唯疯
* All rights reserved.
*
* Brief: FAST特征点提取以及FREAK描述子的图像匹配，基于OpenCV2.4.8
* Version: 1.0
* Author: 唯疯
* Date: 2016/07/21
* Address: 广州&北京
************************************************************************/
#include <opencv2/core/core.hpp>
#include <opencv2/features2d/features2d.hpp>
#include <opencv2/highgui/highgui.hpp>
#include <opencv2/nonfree/features2d.hpp>
#include <opencv2/legacy/legacy.hpp>
#include <iostream>
#include <vector>
 
using namespace std;
using namespace cv;
 
int main()
{
    Mat img1_src = imread("im5.jpg",0);
    Mat img2_src = imread("im6.jpg",0);
    //FastFeatureDetector fast(40);
    SurfFeatureDetector fast(2000,4);
    FREAK extractor;
    vector<KeyPoint> keypoints1,keypoints2;
    Mat descriptor1,descriptor2;
    vector<DMatch> final_matches; 
    vector<DMatch> matches;
 
    double t = (double)getTickCount();
    fast.detect(img1_src,keypoints1);
    fast.detect(img2_src,keypoints2);
    //drawKeypoints(img1_src,keypoints1,img1_src,Scalar(0,255,0));
    //drawKeypoints(img2_src,keypoints2,img2_src,Scalar(0,255,0));//问题在这里！！！醉了，这里的问题，浪费了我5天，欧耶，就是整整5天，由于我想在这里看一看检测出来的特征点是啥样的，就跟父母想第一眼就立刻看到刚出生的婴儿是一个心情的。结果，后来特征匹配就几乎没有什么正确匹配，害我还以为是FREAK这个描述子有问题呢。于是就各种找问题，看论文，翻墙逛论坛。最后一个不经意间发现了。问题就是：这俩个语句是把特征点又原封不动的画到了img1_src中，也就是原图像里面，而后来我进行特征点描述的时候，就直接在画满了特征点的图片下进行描述，而不是原图！不是原图啊！是充满了特征点的图片！所以后期再进行匹配的时候，显然，各种乱匹配，就跟隔壁家小狗似的，见了猫都想干坏事。于是乎，我直接注释掉了这两句！
    extractor.compute(img1_src,keypoints1,descriptor1);
    extractor.compute(img2_src,keypoints2,descriptor2);
    BFMatcher matcher(NORM_HAMMING,true);//暴力匹配，并且进行crosscheck，就是说第二个参数选择true。
    matcher.match(descriptor1,descriptor2,matches);
    final_matches=matches;
    cout<<"number of total_matches : "<<final_matches.size()<<endl;
 
//接下来是RANSAC剔除误匹配
    vector<Point2f> querymatches, trainmatches;
    vector<KeyPoint> p1,p2;
    for(int i=0;i<final_matches.size();i++)
    {
        p1.push_back(keypoints1[final_matches[i].queryIdx]);
        p2.push_back(keypoints2[final_matches[i].trainIdx]);
    }
    for(int i=0;i<p1.size();i++)
    {
        querymatches.push_back(p1[i].pt);
        trainmatches.push_back(p2[i].pt);
    }
    cout<<querymatches[1]<<" and "<<trainmatches[1]<<endl;
    vector<uchar> status;
    Mat h = findHomography(querymatches,trainmatches,status,CV_FM_RANSAC,10);
    int index=0;
    vector<DMatch> super_final_matches;
    for (int i=0;i<final_matches.size();i++)
    {
        cout<<status[i]；
        if (status[i] != 0)
        {
        super_final_matches.push_back(final_matches[i]);
            index++;
        }
    }
    cout<<"number of inlier_matches : "<<index<<endl;
 
    Mat imgMatch;
    drawMatches(img1_src,keypoints1,img2_src,keypoints2,super_final_matches,imgMatch);
    imshow("imgMatch",imgMatch);
 
    t = ((double)getTickCount()-t)/getTickFrequency();
    cout<<" total time [s] : "<<t<<endl;
    waitKey(0);
    return 0;
}