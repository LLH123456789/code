#include<opencv2/opencv.hpp>
#include<iostream>
using namespace std;
using namespace cv;
#include<vector>

Mat img1 = imread("C:\\Users\\Lenovo Y9000K\\Desktop\\match\\Left1.bmp");//读入图像
Mat img1_gray;
Mat img2 = imread("C:\\Users\\Lenovo Y9000K\\Desktop\\match\\Right1.bmp");//读入图像
Mat img2_gray;
int thresh = 300;
RNG rng(12345);

void PointsToKeyPoints(vector<Point2f>corner1, vector<KeyPoint>& keypoints_1)
{
	for (size_t i = 0; i < corner1.size(); i++) {
		keypoints_1.push_back(KeyPoint(corner1[i], 1.f));
	}
}

//回调函数
void on_harris(int, void*)
{
	vector<Point2f>corner1;
	goodFeaturesToTrack(img1_gray, corner1, thresh, 0.01, 0.1, Mat(), 3, false, 0.04);

	vector<Point2f>corner2;
	goodFeaturesToTrack(img2_gray, corner2, thresh, 0.01, 0.1, Mat(), 3, false, 0.04);
	//cout << "检测到的角点数量为：" << corner1.size() << endl;

	//以随机颜色绘制出角点
	for (int i = 0; i < corner1.size(); i++)
	{
		circle(img1, corner1[i], 4, Scalar(rng.uniform(0, 255), rng.uniform(0, 255), rng.uniform(0, 255)), 2, 8, 0);
	}
	imshow("【原始图像1】", img1);

	//以随机颜色绘制出角点
	for (int i = 0; i < corner2.size(); i++)
	{
		circle(img2, corner2[i], 4, Scalar(rng.uniform(0, 255), rng.uniform(0, 255), rng.uniform(0, 255)), 2, 8, 0);
	}
	imshow("【原始图像2】", img2);

	//  调用cornerSubPix函数计算出亚像素角点的位置
	TermCriteria criteria = TermCriteria(TermCriteria::EPS + TermCriteria::MAX_ITER, 40, 0.001);
	cornerSubPix(img1_gray, corner1, Size(5, 5), Size(-1, -1), criteria);
	cornerSubPix(img2_gray, corner2, Size(5, 5), Size(-1, -1), criteria);
	//输出角点信息
	cout << corner1.size() << endl;
	cout << corner2.size() << endl;

	vector<KeyPoint> keypoints_1, keypoints_2;//关键点
	Mat descriptors_1, descriptors_2;//描述子
	Ptr<FeatureDetector> detector = ORB::create();
	Ptr<DescriptorExtractor> descriptor = ORB::create();
	Ptr<DescriptorMatcher> matcher = DescriptorMatcher::create("BruteForce-Hamming");//暴力匹配

	PointsToKeyPoints(corner1, keypoints_1);
	PointsToKeyPoints(corner2, keypoints_2);

	//--第二步根据角点位置计算BRIEF描述子
	descriptor->compute(img1, keypoints_1, descriptors_1);
	descriptor->compute(img2, keypoints_2, descriptors_2);

	//--第三步：对两幅图像中的BRIEF描述子进行匹配，使用Hamming距离
	vector<DMatch> matches;
	matcher->match(descriptors_1, descriptors_2, matches);


	//--第四步：匹配点对筛选
	auto min_max = minmax_element(matches.begin(), matches.end(),
		[](const DMatch& m1, const DMatch& m2) {return m1.distance < m2.distance; });
	double min_dist = min_max.first->distance;
	double max_dist = min_max.second->distance;

	printf("-- Mat dist : %f \n", max_dist);
	printf("-- Mat dist : %f \n", min_dist);


	//当描述子之间的距离大于两倍的最小距离时，即认为匹配有误。但是有时最小距离会非常小，所以要设置一个经验值30作为下限
	vector<DMatch> good_matches;
	for (int i = 0; i < descriptors_1.rows; i++) {
		if (matches[i].distance <= max(2 * min_dist, 30.0)) {
			good_matches.push_back(matches[i]);
		}
	}

	//--第五步：绘制匹配结果
	Mat img_match;
	Mat img_goodmatch;
	drawMatches(img1, keypoints_1, img2, keypoints_2, matches, img_match);
	drawMatches(img1, keypoints_1, img2, keypoints_2, good_matches, img_goodmatch);
	namedWindow("all matches", WINDOW_FREERATIO);
	namedWindow("good matches", WINDOW_FREERATIO);
	imshow("all matches", img_match);
	imshow("good matches", img_goodmatch);

	std::vector<Point2f> obj;
	std::vector<Point2f> scene;
	for (size_t i = 0; i < good_matches.size(); i++)
	{
		//-- Get the keypoints from the good matches
		obj.push_back(keypoints_1[good_matches[i].queryIdx].pt);
		scene.push_back(keypoints_2[good_matches[i].trainIdx].pt);
	}
	Mat H = findHomography(obj, scene, RANSAC);
	//-- Get the corners from the image_1 ( the object to be "detected" )
	std::vector<Point2f> obj_corners(4);
	obj_corners[0] = cvPoint(0, 0); obj_corners[1] = cvPoint(img1.cols, 0);
	obj_corners[2] = cvPoint(img1.cols, img1.rows); obj_corners[3] = cvPoint(0, img1.rows);
	std::vector<Point2f> scene_corners(4);
	perspectiveTransform(obj_corners, scene_corners, H);
	//-- Draw lines between the corners (the mapped object in the scene - image_2 )
	line(img_goodmatch, scene_corners[0] + Point2f(img1.cols, 0), scene_corners[1] + Point2f(img1.cols, 0), Scalar(0, 255, 0), 8);
	line(img_goodmatch, scene_corners[1] + Point2f(img1.cols, 0), scene_corners[2] + Point2f(img1.cols, 0), Scalar(0, 255, 0), 8);
	line(img_goodmatch, scene_corners[2] + Point2f(img1.cols, 0), scene_corners[3] + Point2f(img1.cols, 0), Scalar(0, 255, 0), 8);
	line(img_goodmatch, scene_corners[3] + Point2f(img1.cols, 0), scene_corners[0] + Point2f(img1.cols, 0), Scalar(0, 255, 0), 8);
	//-- Show detected matches
	namedWindow("Good Matches & Object detection", WINDOW_FREERATIO),
		imshow("Good Matches & Object detection", img_goodmatch);

}

int main()
{
	/*img1 = img1(Rect(1000, 0, 400, 400));
	img2 = img2(Rect(1000, 0, 400, 400));*/
	img1_gray = img1.clone();
	cvtColor(img1_gray, img1_gray, COLOR_RGB2GRAY);
	namedWindow("【原始图像1】", WINDOW_FREERATIO);
	img2_gray = img2.clone();
	cvtColor(img2_gray, img2_gray, COLOR_RGB2GRAY);
	namedWindow("【原始图像2】", WINDOW_FREERATIO);
	createTrackbar("【最大角点数】", "【原始图像1】", &thresh, 500, on_harris);
	on_harris(0, 0);
	waitKey(0);
	return 0;
}