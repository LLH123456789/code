int sift(cv::Mat dbImg, cv::Mat testImg, cv::Mat &outImg){
    cv::Ptr<cv::SIFT> detector = cv::SIFT::create(500);
    std::vector<cv::KeyPoint> keypoints1, keypoints2;
    cv::Mat descriptor1, descriptor2;
    dbg("计算SIFT关键点和特征描述子");
    detector->detectAndCompute(dbImg, cv::Mat(), keypoints1, descriptor1);
    detector->detectAndCompute(testImg, cv::Mat(), keypoints2, descriptor2);
    if (keypoints1.empty() || keypoints2.empty())
	{
		dbg("sift key points empty");
		return 0;
	}

    cv::Ptr<cv::DescriptorMatcher> matcher = cv::DescriptorMatcher::create(cv::DescriptorMatcher::FLANNBASED);
    std::vector<std::vector<cv::DMatch>> matches;
    //使用KNN-matching算法，令K=2。则每个match得到两个最接近的descriptor，然后计算最接近距离和次接近距离之间的比值，当比值大于既定值时，才作为最终match。
    matcher->knnMatch(descriptor1, descriptor2, matches, 2);

    if(matches.empty()){
        dbg("sift matched points is empty");
        return 0;
    }
    if(matches.size()<4){
        dbg("sift matched points is less than 4");
        return 0;
    }
    dbg("匹配点对数：", matches.size());
    dbg("去除错误的匹配点");
    // Lowe's策略：这两个关键点中，如果最近的距离除以次近的距离得到的比率ratio少于某个阈值T，则接受这一对匹配点
    //结果表明ratio取值在0.4~0.6之间最佳，小于0.4的很少有匹配点，大于0.6的则存在大量错误匹配点
    const float ratio_thresh = 0.6f;
    std::vector<cv::DMatch> good_matches;
    for(size_t i=0; i<matches.size(); ++i){
        if(matches[i][0].distance < ratio_thresh*matches[i][1].distance ){
            good_matches.push_back(matches[i][0]);
        }
    }
    cv::Mat img_good_matches;
    cv::drawMatches(dbImg, keypoints1, testImg, keypoints2, 
        good_matches, img_good_matches, cv::Scalar::all(-1), cv::Scalar::all(-1), 
        std::vector<char>(), cv::DrawMatchesFlags::NOT_DRAW_SINGLE_POINTS);

    cv::imwrite("img_good_matches.jpg", img_good_matches); //保存图像
    dbg("匹配点对数：", good_matches.size());

    //获取匹配特征点对的坐标值
    std::vector<cv::Point2f> points_dbImg, points_testImg;
	for (size_t i = 0; i < good_matches.size(); i++)
	{
		points_dbImg.push_back(keypoints1[good_matches[i].queryIdx].pt);//.pt对应坐标
		points_testImg.push_back(keypoints2[good_matches[i].trainIdx].pt);
	}

    //RANSAC算法进一步剔除误匹配点对
    std::vector<uchar>inliers;
    cv::findFundamentalMat(points_dbImg, points_testImg, inliers, cv::FM_RANSAC, 3);//p1 p2必须为float型
    // cv::Mat h2 = cv::findHomography(points_dbImg, points_testImg, inliers, cv::RANSAC);
    std::vector<cv::DMatch> good_matches_ransac;
    std::vector<cv::Point2f> dbImgPointsOk;
    std::vector<cv::Point2f> testImgPointsOk;
    for (size_t i = 0; i < inliers.size(); ++i){
        if(inliers[i]){
            good_matches_ransac.push_back(good_matches[i]);
            dbImgPointsOk.push_back(points_dbImg[i]);       //图1的点
            testImgPointsOk.push_back(points_testImg[i]);     //图2的对应点
        }
    }
    dbg("匹配点对数RANSAC：", good_matches_ransac.size());

    cv::Mat img_matches_ransac;
    cv::drawMatches(dbImg, keypoints1, testImg, keypoints2, 
        good_matches_ransac, img_matches_ransac, cv::Scalar::all(-1), cv::Scalar::all(-1), 
        std::vector<char>(), cv::DrawMatchesFlags::NOT_DRAW_SINGLE_POINTS);

    cv::imwrite("img_matches_ransac.jpg", img_matches_ransac); //保存图像
    //计算仿射变换矩阵
    //cv::estimateAffine2D(InputArray src,InputArray dst)
    //src变换之前的关键点Array， dst变换之后的关键点Array，求从src到dst的变换矩阵
    //我们要将输入的测试图像坐标进行变换，变换到数据库里的图像坐标
    cv::Mat T = cv::estimateAffine2D(testImgPointsOk, dbImgPointsOk);
    // cv::Mat T = cv::findHomography(testImgPointsOk, dbImgPointsOk, cv::RANSAC);
    if(!T.empty()) dbg("输出仿射变换矩阵T", T);
    else{
        dbg("变换矩阵为空");
        return 0;
    }
    cv::Size refSize(dbImg.cols, dbImg.rows);
    dbg(refSize);
 
    // cv::warpPerspective(testImg, outImg, T, refSize);
    //应用仿射矩阵T，对输入的图像进行像素重采样
    cv::warpAffine(testImg, outImg, T, refSize, cv::INTER_CUBIC);
	if (outImg.empty())
	{
		dbg("warpPerspective image output empty");
		return 0;
	}
    return 1;
}